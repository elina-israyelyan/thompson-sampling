{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Thompson Sampling Welcome to the Thompson Sampling documentation. Documented by Elina Israyelyan","title":"Home"},{"location":"#thompson-sampling","text":"Welcome to the Thompson Sampling documentation. Documented by Elina Israyelyan","title":"Thompson Sampling"},{"location":"examples/","text":"examples.plot_current_distribution model_beta_visualisation () Plot the graph of Beta distribution's pdf function for each arm after fitting the model. Source code in examples/plot_current_distribution.py def model_beta_visualisation (): \"\"\" Plot the graph of Beta distribution's pdf function for each arm after fitting the model. \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating sample data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 0 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = BetaDistributionModel () # instantiating the model data = pd . DataFrame ( data ) model . fit ( data ) model . plot_current_pdf () # plotting the current pdf function model_normal_visualisation () Plot the graph of Normal distribution's pdf function for each arm after fitting the model. Source code in examples/plot_current_distribution.py def model_normal_visualisation (): \"\"\" Plot the graph of Normal distribution's pdf function for each arm after fitting the model. \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating sample data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 0 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = NormalDistributionModel () # instantiating the model data = pd . DataFrame ( data ) model . fit ( data ) # fitting the model model . plot_current_pdf ( range_of_plot = ( - 1 , 1 ), plot_frequency = 100 ) # plotting the current pdf function examples.plot_dynamic_beta_distribution model_beta_visualisation () Example for plotting a dynamic graph assuming the data should have a beta distribution. The plot has the graphs of beta distribution pdf function for all the time points Source code in examples/plot_dynamic_beta_distribution.py def model_beta_visualisation (): \"\"\" Example for plotting a dynamic graph assuming the data should have a beta distribution. The plot has the graphs of beta distribution pdf function for all the time points \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = BetaDistributionModel () # instantiating the model data = pd . DataFrame ( data ) a_b_lists = get_dist_params ( model , data ) # get a b parameters for Beta distribution for each timestamp fig = plot_dist_over_time ( a_b_lists , beta ) # plot the dynamic graph fig . show () examples.plot_dynamic_normal_distribution model_normal_visualisation () Example for plotting a dynamic graph assuming the data should have a normal distribution. The plot has the graphs of normal distribution's pdf function for all the time points Source code in examples/plot_dynamic_normal_distribution.py def model_normal_visualisation (): \"\"\" Example for plotting a dynamic graph assuming the data should have a normal distribution. The plot has the graphs of normal distribution's pdf function for all the time points \"\"\" data = { 'B1' : [ 0.5 ] * 50 + [ 0.9 ] * 100 , # generating data 'B2' : [ random . uniform ( 0 , 1 ) for x in range ( 50 )] + [ 0.9 ] * 100 , 'B3' : [ random . uniform ( 0 , 1 ) for x in range ( 150 )]} model = NormalDistributionModel () # instantiating the model data = pd . DataFrame ( data ) myu_sigma_lists = get_dist_params ( model , data ) # get the myu and sigma parameters for all the time points fig = plot_dist_over_time ( myu_sigma_lists , norm , ( 0 , 1 )) # plot fig . show ()","title":"Examples"},{"location":"examples/#examples.plot_current_distribution","text":"","title":"plot_current_distribution"},{"location":"examples/#examples.plot_current_distribution.model_beta_visualisation","text":"Plot the graph of Beta distribution's pdf function for each arm after fitting the model. Source code in examples/plot_current_distribution.py def model_beta_visualisation (): \"\"\" Plot the graph of Beta distribution's pdf function for each arm after fitting the model. \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating sample data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 0 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = BetaDistributionModel () # instantiating the model data = pd . DataFrame ( data ) model . fit ( data ) model . plot_current_pdf () # plotting the current pdf function","title":"model_beta_visualisation()"},{"location":"examples/#examples.plot_current_distribution.model_normal_visualisation","text":"Plot the graph of Normal distribution's pdf function for each arm after fitting the model. Source code in examples/plot_current_distribution.py def model_normal_visualisation (): \"\"\" Plot the graph of Normal distribution's pdf function for each arm after fitting the model. \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating sample data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 0 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = NormalDistributionModel () # instantiating the model data = pd . DataFrame ( data ) model . fit ( data ) # fitting the model model . plot_current_pdf ( range_of_plot = ( - 1 , 1 ), plot_frequency = 100 ) # plotting the current pdf function","title":"model_normal_visualisation()"},{"location":"examples/#examples.plot_dynamic_beta_distribution","text":"","title":"plot_dynamic_beta_distribution"},{"location":"examples/#examples.plot_dynamic_beta_distribution.model_beta_visualisation","text":"Example for plotting a dynamic graph assuming the data should have a beta distribution. The plot has the graphs of beta distribution pdf function for all the time points Source code in examples/plot_dynamic_beta_distribution.py def model_beta_visualisation (): \"\"\" Example for plotting a dynamic graph assuming the data should have a beta distribution. The plot has the graphs of beta distribution pdf function for all the time points \"\"\" data = { 'B1' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 50 + [ 0 ] * 50 , # generating data 'B2' : [ random . randint ( 0 , 1 ) for x in range ( 50 )] + [ 1 ] * 100 , 'B3' : [ random . randint ( 0 , 1 ) for x in range ( 150 )]} model = BetaDistributionModel () # instantiating the model data = pd . DataFrame ( data ) a_b_lists = get_dist_params ( model , data ) # get a b parameters for Beta distribution for each timestamp fig = plot_dist_over_time ( a_b_lists , beta ) # plot the dynamic graph fig . show ()","title":"model_beta_visualisation()"},{"location":"examples/#examples.plot_dynamic_normal_distribution","text":"","title":"plot_dynamic_normal_distribution"},{"location":"examples/#examples.plot_dynamic_normal_distribution.model_normal_visualisation","text":"Example for plotting a dynamic graph assuming the data should have a normal distribution. The plot has the graphs of normal distribution's pdf function for all the time points Source code in examples/plot_dynamic_normal_distribution.py def model_normal_visualisation (): \"\"\" Example for plotting a dynamic graph assuming the data should have a normal distribution. The plot has the graphs of normal distribution's pdf function for all the time points \"\"\" data = { 'B1' : [ 0.5 ] * 50 + [ 0.9 ] * 100 , # generating data 'B2' : [ random . uniform ( 0 , 1 ) for x in range ( 50 )] + [ 0.9 ] * 100 , 'B3' : [ random . uniform ( 0 , 1 ) for x in range ( 150 )]} model = NormalDistributionModel () # instantiating the model data = pd . DataFrame ( data ) myu_sigma_lists = get_dist_params ( model , data ) # get the myu and sigma parameters for all the time points fig = plot_dist_over_time ( myu_sigma_lists , norm , ( 0 , 1 )) # plot fig . show ()","title":"model_normal_visualisation()"},{"location":"installation/","text":"Getting Started Installation To install the Thompson Sampling package run the following. pip install -e .","title":"Installation"},{"location":"installation/#getting-started","text":"","title":"Getting Started"},{"location":"installation/#installation","text":"To install the Thompson Sampling package run the following. pip install -e .","title":"Installation"},{"location":"model/","text":"model.base BaseModel Source code in model/base.py class BaseModel : def __init__ ( self ): pass def predict ( self ): \"\"\" Get prediction on the current data. Returns ------- None \"\"\" pass def predict_proba ( self ): \"\"\" Get probabilities of prediction for the current data. Returns ------- None \"\"\" pass def fit ( self , data ): \"\"\" Method to fit the data to the model. Parameters ---------- data : optional Data which the model should fit to. Returns ------- None \"\"\" pass def save_model ( self , save_path ): \"\"\" Method to save the model to the path provided. Parameters ---------- save_path : str Path where the model should be saved Returns ------- None \"\"\" pass def load_model ( self , load_path ): \"\"\" Method to load the model from the given path. Parameters ---------- load_path : str Path of the model which should be loaded for the current instance. Returns ------- None \"\"\" pass fit ( self , data ) Method to fit the data to the model. Parameters: Name Type Description Default data optional Data which the model should fit to. required Returns: Type Description None Source code in model/base.py def fit ( self , data ): \"\"\" Method to fit the data to the model. Parameters ---------- data : optional Data which the model should fit to. Returns ------- None \"\"\" pass load_model ( self , load_path ) Method to load the model from the given path. Parameters: Name Type Description Default load_path str Path of the model which should be loaded for the current instance. required Returns: Type Description None Source code in model/base.py def load_model ( self , load_path ): \"\"\" Method to load the model from the given path. Parameters ---------- load_path : str Path of the model which should be loaded for the current instance. Returns ------- None \"\"\" pass predict ( self ) Get prediction on the current data. Returns: Type Description None Source code in model/base.py def predict ( self ): \"\"\" Get prediction on the current data. Returns ------- None \"\"\" pass predict_proba ( self ) Get probabilities of prediction for the current data. Returns: Type Description None Source code in model/base.py def predict_proba ( self ): \"\"\" Get probabilities of prediction for the current data. Returns ------- None \"\"\" pass save_model ( self , save_path ) Method to save the model to the path provided. Parameters: Name Type Description Default save_path str Path where the model should be saved required Returns: Type Description None Source code in model/base.py def save_model ( self , save_path ): \"\"\" Method to save the model to the path provided. Parameters ---------- save_path : str Path where the model should be saved Returns ------- None \"\"\" pass model.beta_distribution BetaDistributionModel ( BaseModel ) Source code in model/beta_distribution.py class BetaDistributionModel ( BaseModel ): def __init__ ( self ): super () . __init__ () self . arm_dist_params = None self . penalties = None self . number_of_plays = None self . arm_labels = [] self . predicted_best_rewards = None @property def arm_labels ( self ): return self . _arm_labels @arm_labels . setter def arm_labels ( self , arm_labels ): # updating all parameters of the model self . arm_dist_params = [( 1 , 1 )] * len ( arm_labels ) self . penalties = [ 0 ] * len ( arm_labels ) self . number_of_plays = [ 0 ] * len ( arm_labels ) self . _arm_labels = arm_labels def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of beta distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : # check if model should be trained from scratch self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : is_reward = data [ best_arm_label ] . tolist ()[ i ] # get the reward value except KeyError : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue if is_reward == 1 or is_reward == 0 : # check if reward is provided correctly in the data self . penalties [ best_arm ] += 1 - is_reward self . number_of_plays [ best_arm ] += 1 else : raise ValueError ( \"The data is not complete. Required data contains binary values only.\" ) if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over for arm in range ( len ( self . arm_labels )): # update distribution parameters num_of_fails = self . penalties [ arm ] num_of_success = self . number_of_plays [ arm ] - num_of_fails self . arm_dist_params [ arm ] = ( 1 + num_of_success , 1 + num_of_fails ) def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : # check if current arm gave the maximum reward rate and update the maximum. max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ] def predict_proba ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns ------- str, float The name of the arm which gave the most probability to have a reward and the probability. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ], max_proba def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # opening a pickle file pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"penalties\" : self . penalties , \"number_of_plays\" : self . number_of_plays }, f , protocol = pickle . HIGHEST_PROTOCOL ) # save parameters of model def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # open and read the pickle file model = pickle . load ( f ) # loading the model's parameters self . arm_dist_params , self . arm_labels , self . penalties , self . number_of_plays = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"penalties\" ], model [ \"number_of_plays\" ]) def plot_current_pdf ( self , label : str = None ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = beta ( * dist_args ) # getting the distribution fig . add_trace ( go . Scatter ( visible = True , # plotting figure and make it visible line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = beta ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) fig . show () def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig fit ( self , data , prefit = True , exploration_time = 10 ) Method to fit the data to the Binomial Thompson Sampling model Parameters: Name Type Description Default data DataFrame Data to fit the model. required prefit bool If True use the previous, trained parameters of beta distribution for each arm. True exploration_time int The amount of time points to explore before updating the distribution parameters. 10 Returns: Type Description None Source code in model/beta_distribution.py def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of beta distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : # check if model should be trained from scratch self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : is_reward = data [ best_arm_label ] . tolist ()[ i ] # get the reward value except KeyError : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue if is_reward == 1 or is_reward == 0 : # check if reward is provided correctly in the data self . penalties [ best_arm ] += 1 - is_reward self . number_of_plays [ best_arm ] += 1 else : raise ValueError ( \"The data is not complete. Required data contains binary values only.\" ) if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over for arm in range ( len ( self . arm_labels )): # update distribution parameters num_of_fails = self . penalties [ arm ] num_of_success = self . number_of_plays [ arm ] - num_of_fails self . arm_dist_params [ arm ] = ( 1 + num_of_success , 1 + num_of_fails ) get_best_reward ( self , n = 200 ) Get best reward along n predictions. Parameters: Name Type Description Default n int The number of iterations for prediction. 200 Returns: Type Description str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. Source code in model/beta_distribution.py def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) load_model ( self , load_path = './' , version = 'latest' ) Load model from the mentioned path. Parameters: Name Type Description Default load_path str Path from which the model should be loaded. './' version str The version of the model which should be loaded. 'latest' Returns: Type Description None Loads the parameters of the model from the path. Source code in model/beta_distribution.py def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # open and read the pickle file model = pickle . load ( f ) # loading the model's parameters self . arm_dist_params , self . arm_labels , self . penalties , self . number_of_plays = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"penalties\" ], model [ \"number_of_plays\" ]) plot_best_rewards ( self ) Plot the histogram of best rewards for n predicts. Returns: Type Description go.Figure The histogram of best rewards Source code in model/beta_distribution.py def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig plot_current_pdf ( self , label = None ) Plot the pdf function of the current timestamp. Parameters: Name Type Description Default label str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. None Returns: Type Description None Source code in model/beta_distribution.py def plot_current_pdf ( self , label : str = None ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = beta ( * dist_args ) # getting the distribution fig . add_trace ( go . Scatter ( visible = True , # plotting figure and make it visible line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = beta ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) fig . show () predict ( self ) Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/beta_distribution.py def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : # check if current arm gave the maximum reward rate and update the maximum. max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ] predict_proba ( self ) Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns: Type Description str, float The name of the arm which gave the most probability to have a reward and the probability. Source code in model/beta_distribution.py def predict_proba ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns ------- str, float The name of the arm which gave the most probability to have a reward and the probability. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ], max_proba save_model ( self , save_path = './' , version = 'latest' ) Save the model parameters in the mentioned path. Parameters: Name Type Description Default save_path str Path where the model needs to be saved. './' version str The version suffix which will be added to the model path. 'latest' Returns: Type Description None Saves the model in the save_path. Source code in model/beta_distribution.py def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # opening a pickle file pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"penalties\" : self . penalties , \"number_of_plays\" : self . number_of_plays }, f , protocol = pickle . HIGHEST_PROTOCOL ) # save parameters of model model.normal_distribution NormalDistributionModel ( BaseModel ) Source code in model/normal_distribution.py class NormalDistributionModel ( BaseModel ): def __init__ ( self ): super () . __init__ () self . arm_dist_params = None self . sum_of_rewards = None self . arm_labels = [] self . predicted_best_rewards = None @property def arm_labels ( self ): return self . _arm_labels @arm_labels . setter def arm_labels ( self , arm_labels ): self . number_of_plays = [ 0 ] * len ( arm_labels ) self . arm_dist_params = [( 0 , 1 )] * len ( arm_labels ) # giving the starting number_of_plays, means and sigmas self . sum_of_rewards = [ 0 ] * len ( arm_labels ) self . _arm_labels = arm_labels def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of normal distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : reward = data [ best_arm_label ] . tolist ()[ i ] except KeyError as e : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue self . number_of_plays [ best_arm ] += 1 self . sum_of_rewards [ best_arm ] += reward if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over and update the parameters for arm in range ( len ( self . arm_labels )): number_of_plays = self . number_of_plays [ arm ] self . arm_dist_params [ arm ] = ( ( 1 / ( number_of_plays + 1 )) * self . sum_of_rewards [ arm ], 1 / ( number_of_plays + 1 )) def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : # check if current arm gave the maximum reward rate and update the maximum. max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ] def predict_reward ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ], max_value def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # pickle the model's parameters pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"number_of_plays\" : self . number_of_plays , \"sum_of_rewards\" : self . sum_of_rewards }, f , protocol = pickle . HIGHEST_PROTOCOL ) def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # load pickle file model = pickle . load ( f ) self . arm_dist_params , self . arm_labels , self . number_of_plays , self . sum_of_rewards = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"number_of_plays\" ], model [ \"sum_of_rewards\" ]) # update parameters def plot_current_pdf ( self , label : str = None , range_of_plot : tuple = ( - 1 , 1 ), plot_frequency : int = 100 ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. range_of_plot: tuple The range of figure for which the plot needs to be shown. plot_frequency: int The frequency of plot on the figure. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = norm ( * dist_args ) # get the distribution fig . add_trace ( go . Scatter ( visible = True , # create the figure of distribution's pdf line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = norm ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) fig . show () def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig fit ( self , data , prefit = True , exploration_time = 10 ) Method to fit the data to the Binomial Thompson Sampling model Parameters: Name Type Description Default data DataFrame Data to fit the model. required prefit bool If True use the previous, trained parameters of normal distribution for each arm. True exploration_time int The amount of time points to explore before updating the distribution parameters. 10 Returns: Type Description None Source code in model/normal_distribution.py def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of normal distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : reward = data [ best_arm_label ] . tolist ()[ i ] except KeyError as e : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue self . number_of_plays [ best_arm ] += 1 self . sum_of_rewards [ best_arm ] += reward if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over and update the parameters for arm in range ( len ( self . arm_labels )): number_of_plays = self . number_of_plays [ arm ] self . arm_dist_params [ arm ] = ( ( 1 / ( number_of_plays + 1 )) * self . sum_of_rewards [ arm ], 1 / ( number_of_plays + 1 )) get_best_reward ( self , n = 200 ) Get best reward along n predictions. Parameters: Name Type Description Default n int The number of iterations for prediction. 200 Returns: Type Description str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. Source code in model/normal_distribution.py def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) load_model ( self , load_path = './' , version = 'latest' ) Load model from the mentioned path. Parameters: Name Type Description Default load_path str Path from which the model should be loaded. './' version str The version of the model which should be loaded. 'latest' Returns: Type Description None Loads the parameters of the model from the path. Source code in model/normal_distribution.py def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # load pickle file model = pickle . load ( f ) self . arm_dist_params , self . arm_labels , self . number_of_plays , self . sum_of_rewards = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"number_of_plays\" ], model [ \"sum_of_rewards\" ]) # update parameters plot_best_rewards ( self ) Plot the histogram of best rewards for n predicts. Returns: Type Description go.Figure The histogram of best rewards Source code in model/normal_distribution.py def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig plot_current_pdf ( self , label = None , range_of_plot = ( - 1 , 1 ), plot_frequency = 100 ) Plot the pdf function of the current timestamp. Parameters: Name Type Description Default label str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. None range_of_plot tuple The range of figure for which the plot needs to be shown. (-1, 1) plot_frequency int The frequency of plot on the figure. 100 Returns: Type Description None Source code in model/normal_distribution.py def plot_current_pdf ( self , label : str = None , range_of_plot : tuple = ( - 1 , 1 ), plot_frequency : int = 100 ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. range_of_plot: tuple The range of figure for which the plot needs to be shown. plot_frequency: int The frequency of plot on the figure. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = norm ( * dist_args ) # get the distribution fig . add_trace ( go . Scatter ( visible = True , # create the figure of distribution's pdf line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = norm ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) fig . show () predict ( self ) Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/normal_distribution.py def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : # check if current arm gave the maximum reward rate and update the maximum. max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ] predict_reward ( self ) Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/normal_distribution.py def predict_reward ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ], max_value save_model ( self , save_path = './' , version = 'latest' ) Save the model parameters in the mentioned path. Parameters: Name Type Description Default save_path str Path where the model needs to be saved. './' version str The version suffix which will be added to the model path. 'latest' Returns: Type Description None Saves the model in the save_path. Source code in model/normal_distribution.py def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # pickle the model's parameters pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"number_of_plays\" : self . number_of_plays , \"sum_of_rewards\" : self . sum_of_rewards }, f , protocol = pickle . HIGHEST_PROTOCOL )","title":"Model"},{"location":"model/#model.base","text":"","title":"base"},{"location":"model/#model.base.BaseModel","text":"Source code in model/base.py class BaseModel : def __init__ ( self ): pass def predict ( self ): \"\"\" Get prediction on the current data. Returns ------- None \"\"\" pass def predict_proba ( self ): \"\"\" Get probabilities of prediction for the current data. Returns ------- None \"\"\" pass def fit ( self , data ): \"\"\" Method to fit the data to the model. Parameters ---------- data : optional Data which the model should fit to. Returns ------- None \"\"\" pass def save_model ( self , save_path ): \"\"\" Method to save the model to the path provided. Parameters ---------- save_path : str Path where the model should be saved Returns ------- None \"\"\" pass def load_model ( self , load_path ): \"\"\" Method to load the model from the given path. Parameters ---------- load_path : str Path of the model which should be loaded for the current instance. Returns ------- None \"\"\" pass","title":"BaseModel"},{"location":"model/#model.base.BaseModel.fit","text":"Method to fit the data to the model. Parameters: Name Type Description Default data optional Data which the model should fit to. required Returns: Type Description None Source code in model/base.py def fit ( self , data ): \"\"\" Method to fit the data to the model. Parameters ---------- data : optional Data which the model should fit to. Returns ------- None \"\"\" pass","title":"fit()"},{"location":"model/#model.base.BaseModel.load_model","text":"Method to load the model from the given path. Parameters: Name Type Description Default load_path str Path of the model which should be loaded for the current instance. required Returns: Type Description None Source code in model/base.py def load_model ( self , load_path ): \"\"\" Method to load the model from the given path. Parameters ---------- load_path : str Path of the model which should be loaded for the current instance. Returns ------- None \"\"\" pass","title":"load_model()"},{"location":"model/#model.base.BaseModel.predict","text":"Get prediction on the current data. Returns: Type Description None Source code in model/base.py def predict ( self ): \"\"\" Get prediction on the current data. Returns ------- None \"\"\" pass","title":"predict()"},{"location":"model/#model.base.BaseModel.predict_proba","text":"Get probabilities of prediction for the current data. Returns: Type Description None Source code in model/base.py def predict_proba ( self ): \"\"\" Get probabilities of prediction for the current data. Returns ------- None \"\"\" pass","title":"predict_proba()"},{"location":"model/#model.base.BaseModel.save_model","text":"Method to save the model to the path provided. Parameters: Name Type Description Default save_path str Path where the model should be saved required Returns: Type Description None Source code in model/base.py def save_model ( self , save_path ): \"\"\" Method to save the model to the path provided. Parameters ---------- save_path : str Path where the model should be saved Returns ------- None \"\"\" pass","title":"save_model()"},{"location":"model/#model.beta_distribution","text":"","title":"beta_distribution"},{"location":"model/#model.beta_distribution.BetaDistributionModel","text":"Source code in model/beta_distribution.py class BetaDistributionModel ( BaseModel ): def __init__ ( self ): super () . __init__ () self . arm_dist_params = None self . penalties = None self . number_of_plays = None self . arm_labels = [] self . predicted_best_rewards = None @property def arm_labels ( self ): return self . _arm_labels @arm_labels . setter def arm_labels ( self , arm_labels ): # updating all parameters of the model self . arm_dist_params = [( 1 , 1 )] * len ( arm_labels ) self . penalties = [ 0 ] * len ( arm_labels ) self . number_of_plays = [ 0 ] * len ( arm_labels ) self . _arm_labels = arm_labels def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of beta distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : # check if model should be trained from scratch self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : is_reward = data [ best_arm_label ] . tolist ()[ i ] # get the reward value except KeyError : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue if is_reward == 1 or is_reward == 0 : # check if reward is provided correctly in the data self . penalties [ best_arm ] += 1 - is_reward self . number_of_plays [ best_arm ] += 1 else : raise ValueError ( \"The data is not complete. Required data contains binary values only.\" ) if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over for arm in range ( len ( self . arm_labels )): # update distribution parameters num_of_fails = self . penalties [ arm ] num_of_success = self . number_of_plays [ arm ] - num_of_fails self . arm_dist_params [ arm ] = ( 1 + num_of_success , 1 + num_of_fails ) def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : # check if current arm gave the maximum reward rate and update the maximum. max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ] def predict_proba ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns ------- str, float The name of the arm which gave the most probability to have a reward and the probability. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ], max_proba def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # opening a pickle file pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"penalties\" : self . penalties , \"number_of_plays\" : self . number_of_plays }, f , protocol = pickle . HIGHEST_PROTOCOL ) # save parameters of model def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # open and read the pickle file model = pickle . load ( f ) # loading the model's parameters self . arm_dist_params , self . arm_labels , self . penalties , self . number_of_plays = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"penalties\" ], model [ \"number_of_plays\" ]) def plot_current_pdf ( self , label : str = None ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = beta ( * dist_args ) # getting the distribution fig . add_trace ( go . Scatter ( visible = True , # plotting figure and make it visible line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = beta ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) fig . show () def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig","title":"BetaDistributionModel"},{"location":"model/#model.beta_distribution.BetaDistributionModel.fit","text":"Method to fit the data to the Binomial Thompson Sampling model Parameters: Name Type Description Default data DataFrame Data to fit the model. required prefit bool If True use the previous, trained parameters of beta distribution for each arm. True exploration_time int The amount of time points to explore before updating the distribution parameters. 10 Returns: Type Description None Source code in model/beta_distribution.py def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of beta distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : # check if model should be trained from scratch self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : is_reward = data [ best_arm_label ] . tolist ()[ i ] # get the reward value except KeyError : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue if is_reward == 1 or is_reward == 0 : # check if reward is provided correctly in the data self . penalties [ best_arm ] += 1 - is_reward self . number_of_plays [ best_arm ] += 1 else : raise ValueError ( \"The data is not complete. Required data contains binary values only.\" ) if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over for arm in range ( len ( self . arm_labels )): # update distribution parameters num_of_fails = self . penalties [ arm ] num_of_success = self . number_of_plays [ arm ] - num_of_fails self . arm_dist_params [ arm ] = ( 1 + num_of_success , 1 + num_of_fails )","title":"fit()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.get_best_reward","text":"Get best reward along n predictions. Parameters: Name Type Description Default n int The number of iterations for prediction. 200 Returns: Type Description str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. Source code in model/beta_distribution.py def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best )","title":"get_best_reward()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.load_model","text":"Load model from the mentioned path. Parameters: Name Type Description Default load_path str Path from which the model should be loaded. './' version str The version of the model which should be loaded. 'latest' Returns: Type Description None Loads the parameters of the model from the path. Source code in model/beta_distribution.py def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # open and read the pickle file model = pickle . load ( f ) # loading the model's parameters self . arm_dist_params , self . arm_labels , self . penalties , self . number_of_plays = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"penalties\" ], model [ \"number_of_plays\" ])","title":"load_model()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.plot_best_rewards","text":"Plot the histogram of best rewards for n predicts. Returns: Type Description go.Figure The histogram of best rewards Source code in model/beta_distribution.py def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig","title":"plot_best_rewards()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.plot_current_pdf","text":"Plot the pdf function of the current timestamp. Parameters: Name Type Description Default label str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. None Returns: Type Description None Source code in model/beta_distribution.py def plot_current_pdf ( self , label : str = None ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = beta ( * dist_args ) # getting the distribution fig . add_trace ( go . Scatter ( visible = True , # plotting figure and make it visible line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = beta ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( 0 , 1 , 100 ), y = distribution_func . pdf ( np . linspace ( 0 , 1 , 100 )))) fig . show ()","title":"plot_current_pdf()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.predict","text":"Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/beta_distribution.py def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : # check if current arm gave the maximum reward rate and update the maximum. max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ]","title":"predict()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.predict_proba","text":"Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns: Type Description str, float The name of the arm which gave the most probability to have a reward and the probability. Source code in model/beta_distribution.py def predict_proba ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Same as self.predict() but returns the reward rate as well. Returns ------- str, float The name of the arm which gave the most probability to have a reward and the probability. \"\"\" max_proba = - 1 best_arm = - 1 for arm in range ( len ( self . arm_labels )): a , b = self . arm_dist_params [ arm ] arm_reward_proba = np . random . beta ( a , b ) if arm_reward_proba > max_proba : max_proba = arm_reward_proba best_arm = arm return self . arm_labels [ best_arm ], max_proba","title":"predict_proba()"},{"location":"model/#model.beta_distribution.BetaDistributionModel.save_model","text":"Save the model parameters in the mentioned path. Parameters: Name Type Description Default save_path str Path where the model needs to be saved. './' version str The version suffix which will be added to the model path. 'latest' Returns: Type Description None Saves the model in the save_path. Source code in model/beta_distribution.py def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # opening a pickle file pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"penalties\" : self . penalties , \"number_of_plays\" : self . number_of_plays }, f , protocol = pickle . HIGHEST_PROTOCOL ) # save parameters of model","title":"save_model()"},{"location":"model/#model.normal_distribution","text":"","title":"normal_distribution"},{"location":"model/#model.normal_distribution.NormalDistributionModel","text":"Source code in model/normal_distribution.py class NormalDistributionModel ( BaseModel ): def __init__ ( self ): super () . __init__ () self . arm_dist_params = None self . sum_of_rewards = None self . arm_labels = [] self . predicted_best_rewards = None @property def arm_labels ( self ): return self . _arm_labels @arm_labels . setter def arm_labels ( self , arm_labels ): self . number_of_plays = [ 0 ] * len ( arm_labels ) self . arm_dist_params = [( 0 , 1 )] * len ( arm_labels ) # giving the starting number_of_plays, means and sigmas self . sum_of_rewards = [ 0 ] * len ( arm_labels ) self . _arm_labels = arm_labels def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of normal distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : reward = data [ best_arm_label ] . tolist ()[ i ] except KeyError as e : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue self . number_of_plays [ best_arm ] += 1 self . sum_of_rewards [ best_arm ] += reward if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over and update the parameters for arm in range ( len ( self . arm_labels )): number_of_plays = self . number_of_plays [ arm ] self . arm_dist_params [ arm ] = ( ( 1 / ( number_of_plays + 1 )) * self . sum_of_rewards [ arm ], 1 / ( number_of_plays + 1 )) def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : # check if current arm gave the maximum reward rate and update the maximum. max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ] def predict_reward ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ], max_value def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # pickle the model's parameters pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"number_of_plays\" : self . number_of_plays , \"sum_of_rewards\" : self . sum_of_rewards }, f , protocol = pickle . HIGHEST_PROTOCOL ) def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # load pickle file model = pickle . load ( f ) self . arm_dist_params , self . arm_labels , self . number_of_plays , self . sum_of_rewards = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"number_of_plays\" ], model [ \"sum_of_rewards\" ]) # update parameters def plot_current_pdf ( self , label : str = None , range_of_plot : tuple = ( - 1 , 1 ), plot_frequency : int = 100 ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. range_of_plot: tuple The range of figure for which the plot needs to be shown. plot_frequency: int The frequency of plot on the figure. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = norm ( * dist_args ) # get the distribution fig . add_trace ( go . Scatter ( visible = True , # create the figure of distribution's pdf line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = norm ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) fig . show () def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best ) def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig","title":"NormalDistributionModel"},{"location":"model/#model.normal_distribution.NormalDistributionModel.fit","text":"Method to fit the data to the Binomial Thompson Sampling model Parameters: Name Type Description Default data DataFrame Data to fit the model. required prefit bool If True use the previous, trained parameters of normal distribution for each arm. True exploration_time int The amount of time points to explore before updating the distribution parameters. 10 Returns: Type Description None Source code in model/normal_distribution.py def fit ( self , data : pd . DataFrame , prefit : bool = True , exploration_time : int = 10 ): \"\"\" Method to fit the data to the Binomial Thompson Sampling model Parameters ---------- data : pandas.DataFrame Data to fit the model. prefit : bool If True use the previous, trained parameters of normal distribution for each arm. exploration_time: int The amount of time points to explore before updating the distribution parameters. Returns ------- None \"\"\" if not self . arm_labels or not prefit : self . arm_labels = data . columns . tolist () for i in range ( len ( data )): best_arm_label = self . predict () # get best reward giving arm best_arm = self . arm_labels . index ( best_arm_label ) try : reward = data [ best_arm_label ] . tolist ()[ i ] except KeyError as e : logging . warning ( \"best arm selected was not in the new data, \" \"so we dont know if there is a reward or not\" ) continue self . number_of_plays [ best_arm ] += 1 self . sum_of_rewards [ best_arm ] += reward if sum ( self . number_of_plays ) % exploration_time == 0 : # check if exploration time is over and update the parameters for arm in range ( len ( self . arm_labels )): number_of_plays = self . number_of_plays [ arm ] self . arm_dist_params [ arm ] = ( ( 1 / ( number_of_plays + 1 )) * self . sum_of_rewards [ arm ], 1 / ( number_of_plays + 1 ))","title":"fit()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.get_best_reward","text":"Get best reward along n predictions. Parameters: Name Type Description Default n int The number of iterations for prediction. 200 Returns: Type Description str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. Source code in model/normal_distribution.py def get_best_reward ( self , n : int = 200 ): \"\"\" Get best reward along n predictions. Parameters ---------- n : int The number of iterations for prediction. Returns ------- str The list of best rewards for each iteration is saved to self.predicted_best_rewards and the best reward is returned. \"\"\" predicts_best = [ self . predict () for _ in range ( n )] # do prediction n times self . predicted_best_rewards = predicts_best return mode ( predicts_best )","title":"get_best_reward()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.load_model","text":"Load model from the mentioned path. Parameters: Name Type Description Default load_path str Path from which the model should be loaded. './' version str The version of the model which should be loaded. 'latest' Returns: Type Description None Loads the parameters of the model from the path. Source code in model/normal_distribution.py def load_model ( self , load_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Load model from the mentioned path. Parameters ---------- load_path : str Path from which the model should be loaded. version : str The version of the model which should be loaded. Returns ------- None Loads the parameters of the model from the path. \"\"\" with open ( load_path + \"model_\" + version + \".pkl\" , 'rb' ) as f : # load pickle file model = pickle . load ( f ) self . arm_dist_params , self . arm_labels , self . number_of_plays , self . sum_of_rewards = ( model [ \"arm_dist_params\" ], model [ \"arm_labels\" ], model [ \"number_of_plays\" ], model [ \"sum_of_rewards\" ]) # update parameters","title":"load_model()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.plot_best_rewards","text":"Plot the histogram of best rewards for n predicts. Returns: Type Description go.Figure The histogram of best rewards Source code in model/normal_distribution.py def plot_best_rewards ( self ): \"\"\" Plot the histogram of best rewards for n predicts. Returns ------- go.Figure The histogram of best rewards \"\"\" predicts_best = self . predicted_best_rewards # get the n predictions from best reward calculation fig = go . Figure ( data = [ go . Histogram ( x = predicts_best )]) # make a histogram return fig","title":"plot_best_rewards()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.plot_current_pdf","text":"Plot the pdf function of the current timestamp. Parameters: Name Type Description Default label str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. None range_of_plot tuple The range of figure for which the plot needs to be shown. (-1, 1) plot_frequency int The frequency of plot on the figure. 100 Returns: Type Description None Source code in model/normal_distribution.py def plot_current_pdf ( self , label : str = None , range_of_plot : tuple = ( - 1 , 1 ), plot_frequency : int = 100 ): \"\"\" Plot the pdf function of the current timestamp. Parameters ---------- label : str The label of the arm that needs to be plotted. If None the distributions of all labels will be plotted. range_of_plot: tuple The range of figure for which the plot needs to be shown. plot_frequency: int The frequency of plot on the figure. Returns ------- None \"\"\" fig = go . Figure () if label is None : for label_name , dist_args in zip ( self . arm_labels , self . arm_dist_params ): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label distribution_func = norm ( * dist_args ) # get the distribution fig . add_trace ( go . Scatter ( visible = True , # create the figure of distribution's pdf line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) else : ind_of_arm = self . arm_labels . index ( label ) hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] dist_args = self . arm_dist_params [ ind_of_arm ] distribution_func = norm ( * dist_args ) fig . add_trace ( go . Scatter ( visible = True , line = dict ( color = hexadecimal , width = 6 ), name = label , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , plot_frequency )))) fig . show ()","title":"plot_current_pdf()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.predict","text":"Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/normal_distribution.py def predict ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): # for each arm get a sample from its distribution myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : # check if current arm gave the maximum reward rate and update the maximum. max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ]","title":"predict()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.predict_reward","text":"Predict which arm is the most reward bringing at current time. Returns: Type Description str The name of the arm which gave the most probability to have a reward. Source code in model/normal_distribution.py def predict_reward ( self ): \"\"\" Predict which arm is the most reward bringing at current time. Returns ------- str The name of the arm which gave the most probability to have a reward. \"\"\" max_value = float ( \"-inf\" ) best_arm = - 1 for arm in range ( len ( self . arm_labels )): myu , sigma = self . arm_dist_params [ arm ] arm_reward = np . random . normal ( myu , sigma ) if arm_reward > max_value : max_value = arm_reward best_arm = arm return self . arm_labels [ best_arm ], max_value","title":"predict_reward()"},{"location":"model/#model.normal_distribution.NormalDistributionModel.save_model","text":"Save the model parameters in the mentioned path. Parameters: Name Type Description Default save_path str Path where the model needs to be saved. './' version str The version suffix which will be added to the model path. 'latest' Returns: Type Description None Saves the model in the save_path. Source code in model/normal_distribution.py def save_model ( self , save_path : str = \"./\" , version : str = \"latest\" ): \"\"\" Save the model parameters in the mentioned path. Parameters ---------- save_path : str Path where the model needs to be saved. version : str The version suffix which will be added to the model path. Returns ------- None Saves the model in the save_path. \"\"\" with open ( save_path + \"model_\" + version + \".pkl\" , 'wb' ) as f : # pickle the model's parameters pickle . dump ({ \"arm_dist_params\" : self . arm_dist_params , \"arm_labels\" : self . arm_labels , \"number_of_plays\" : self . number_of_plays , \"sum_of_rewards\" : self . sum_of_rewards }, f , protocol = pickle . HIGHEST_PROTOCOL )","title":"save_model()"},{"location":"utils/","text":"utils.distribution_params get_dist_params ( model = None , data = None , exploration_time = 10 ) Dynamic plot for plotting beta distributions for a,b values given in a_b_lists. Parameters: Name Type Description Default model BaseModel The model of the distribution. None data DataFrame Each column is the label of one choice for which the distributions will be calculated over time. Each row represents a single timestamp. None exploration_time int The exploration time used for fitting the model. 10 Returns: Type Description dict Each key represents the label name and the values are arrays, each index having the distribution parameters of one timestamp. Source code in utils/distribution_params.py def get_dist_params ( model : BaseModel = None , data : pd . DataFrame = None , exploration_time : int = 10 ): \"\"\" Dynamic plot for plotting beta distributions for a,b values given in a_b_lists. Parameters ---------- model: NormalDistributionModel or BetaDistributionModel The model of the distribution. data : dict Each column is the label of one choice for which the distributions will be calculated over time. Each row represents a single timestamp. exploration_time: int The exploration time used for fitting the model. Returns ------- dict Each key represents the label name and the values are arrays, each index having the distribution parameters of one timestamp. \"\"\" dist_params = { k : [] for k in data . columns } exploration_time = exploration_time for i in range ( len ( data )): # fitting data by each timestamp one by one model . fit ( data . iloc [[ i ]], exploration_time = exploration_time ) if i % exploration_time == 0 : for j in range ( len ( list ( data . columns ))): dist_params [ model . arm_labels [ j ]] . append ( model . arm_dist_params [ j ]) # getting distribution parameters return dist_params","title":"Utils"},{"location":"utils/#utils.distribution_params","text":"","title":"distribution_params"},{"location":"utils/#utils.distribution_params.get_dist_params","text":"Dynamic plot for plotting beta distributions for a,b values given in a_b_lists. Parameters: Name Type Description Default model BaseModel The model of the distribution. None data DataFrame Each column is the label of one choice for which the distributions will be calculated over time. Each row represents a single timestamp. None exploration_time int The exploration time used for fitting the model. 10 Returns: Type Description dict Each key represents the label name and the values are arrays, each index having the distribution parameters of one timestamp. Source code in utils/distribution_params.py def get_dist_params ( model : BaseModel = None , data : pd . DataFrame = None , exploration_time : int = 10 ): \"\"\" Dynamic plot for plotting beta distributions for a,b values given in a_b_lists. Parameters ---------- model: NormalDistributionModel or BetaDistributionModel The model of the distribution. data : dict Each column is the label of one choice for which the distributions will be calculated over time. Each row represents a single timestamp. exploration_time: int The exploration time used for fitting the model. Returns ------- dict Each key represents the label name and the values are arrays, each index having the distribution parameters of one timestamp. \"\"\" dist_params = { k : [] for k in data . columns } exploration_time = exploration_time for i in range ( len ( data )): # fitting data by each timestamp one by one model . fit ( data . iloc [[ i ]], exploration_time = exploration_time ) if i % exploration_time == 0 : for j in range ( len ( list ( data . columns ))): dist_params [ model . arm_labels [ j ]] . append ( model . arm_dist_params [ j ]) # getting distribution parameters return dist_params","title":"get_dist_params()"},{"location":"visualisation/","text":"visualisation.dynamic_plots plot_dist_over_time ( dist_params , distribution , range_of_plot = ( 0 , 1 )) Plotting distribution's pdf function as a dynamic graph. Parameters: Name Type Description Default dist_params dict Each key is the label of one choice for which the given distributions will be plotted. Each row represents a timestamp. required distribution rv_continuous The distribution type to plot. required range_of_plot tuple The range of interval for which the plot should be shown. (0, 1) Returns: Type Description plotly.graph_objects.Figure() The figure that combines all the distributions' pdf function over time, for different labels. Source code in visualisation/dynamic_plots.py def plot_dist_over_time ( dist_params : dict , distribution : rv_continuous , range_of_plot : tuple = ( 0 , 1 )): \"\"\" Plotting distribution's pdf function as a dynamic graph. Parameters ---------- dist_params : dict Each key is the label of one choice for which the given distributions will be plotted. Each row represents a timestamp. distribution : rv_continuous The distribution type to plot. range_of_plot: tuple The range of interval for which the plot should be shown. Returns ------- plotly.graph_objects.Figure() The figure that combines all the distributions' pdf function over time, for different labels. \"\"\" fig = go . Figure () for label_name , args_list in dist_params . items (): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label for args in args_list : distribution_func = distribution ( * args ) fig . add_trace ( go . Scatter ( visible = False , line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , 100 )))) # Create and add slider steps = [] for i in range ( round ( len ( fig . data ) / len ( dist_params . keys ()))): step = dict ( method = \"update\" , args = [{ \"visible\" : [ False ] * len ( fig . data )}, { \"title\" : \"PDF function switched to timestamp: \" + str ( i )}], # layout attribute ) for j in range ( len ( dist_params . keys ())): # to get the traces of the same timestamp (that's why we use i+j*len) step [ \"args\" ][ 0 ][ \"visible\" ][ i + j * len ( list ( dist_params . values ())[ 0 ])] = True # make the trace visible steps . append ( step ) sliders = [ dict ( active = 0 , currentvalue = { \"prefix\" : \"Timestamp: \" }, pad = { \"t\" : 100 }, steps = steps )] fig . update_layout ( sliders = sliders ) return fig","title":"Visualisation"},{"location":"visualisation/#visualisation.dynamic_plots","text":"","title":"dynamic_plots"},{"location":"visualisation/#visualisation.dynamic_plots.plot_dist_over_time","text":"Plotting distribution's pdf function as a dynamic graph. Parameters: Name Type Description Default dist_params dict Each key is the label of one choice for which the given distributions will be plotted. Each row represents a timestamp. required distribution rv_continuous The distribution type to plot. required range_of_plot tuple The range of interval for which the plot should be shown. (0, 1) Returns: Type Description plotly.graph_objects.Figure() The figure that combines all the distributions' pdf function over time, for different labels. Source code in visualisation/dynamic_plots.py def plot_dist_over_time ( dist_params : dict , distribution : rv_continuous , range_of_plot : tuple = ( 0 , 1 )): \"\"\" Plotting distribution's pdf function as a dynamic graph. Parameters ---------- dist_params : dict Each key is the label of one choice for which the given distributions will be plotted. Each row represents a timestamp. distribution : rv_continuous The distribution type to plot. range_of_plot: tuple The range of interval for which the plot should be shown. Returns ------- plotly.graph_objects.Figure() The figure that combines all the distributions' pdf function over time, for different labels. \"\"\" fig = go . Figure () for label_name , args_list in dist_params . items (): hexadecimal = [ \"#\" + '' . join ([ random . choice ( 'ABCDEF0123456789' ) for _ in range ( 6 )])][ 0 ] # choosing random colors for each label for args in args_list : distribution_func = distribution ( * args ) fig . add_trace ( go . Scatter ( visible = False , line = dict ( color = hexadecimal , width = 6 ), name = label_name , x = np . linspace ( * range_of_plot , 100 ), y = distribution_func . pdf ( np . linspace ( * range_of_plot , 100 )))) # Create and add slider steps = [] for i in range ( round ( len ( fig . data ) / len ( dist_params . keys ()))): step = dict ( method = \"update\" , args = [{ \"visible\" : [ False ] * len ( fig . data )}, { \"title\" : \"PDF function switched to timestamp: \" + str ( i )}], # layout attribute ) for j in range ( len ( dist_params . keys ())): # to get the traces of the same timestamp (that's why we use i+j*len) step [ \"args\" ][ 0 ][ \"visible\" ][ i + j * len ( list ( dist_params . values ())[ 0 ])] = True # make the trace visible steps . append ( step ) sliders = [ dict ( active = 0 , currentvalue = { \"prefix\" : \"Timestamp: \" }, pad = { \"t\" : 100 }, steps = steps )] fig . update_layout ( sliders = sliders ) return fig","title":"plot_dist_over_time()"}]}